{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2da4baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\asus\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests) (2022.9.14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\asus\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\asus\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\asus\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\asus\\anaconda3\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\asus\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\asus\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\asus\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\asus\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\asus\\anaconda3\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\asus\\anaconda3\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\asus\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\asus\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\asus\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -treamlit (c:\\users\\asus\\anaconda3\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n",
    "!pip install beautifulsoup4\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe00c9d3",
   "metadata": {},
   "source": [
    "1) Write a python program to display all the header tags from wikipedia.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70854fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header tags found on the page:\n",
      "Main Page\n",
      "Welcome to Wikipedia\n",
      "From today's featured article\n",
      "Did you know ...\n",
      "In the news\n",
      "On this day\n",
      "Today's featured picture\n",
      "Other areas of Wikipedia\n",
      "Wikipedia's sister projects\n",
      "Wikipedia languages\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_header_tags(url):\n",
    "    headers = []\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        header_tags = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
    "        for tag in header_tags:\n",
    "            headers.append(tag.text.strip())\n",
    "    return headers\n",
    "\n",
    "def main():\n",
    "    url = 'https://en.wikipedia.org/wiki/Main_Page'\n",
    "    headers = get_header_tags(url)\n",
    "    if headers:\n",
    "        print(\"Header tags found on the page:\")\n",
    "        for header in headers:\n",
    "            print(header)\n",
    "    else:\n",
    "        print(\"No header tags found on the page.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a595da8",
   "metadata": {},
   "source": [
    "2) Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year\n",
    "of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20ad2b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve data from IMDb.\n",
      "No data retrieved.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def get_top_100_movies():\n",
    "    url = \"https://www.imdb.com/chart/top\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        movies = []\n",
    "        for movie in soup.find_all('tr'):\n",
    "            title_column = movie.find('td', class_='titleColumn')\n",
    "            rating_column = movie.find('td', class_='ratingColumn imdbRating')\n",
    "            if title_column and rating_column:\n",
    "                title = title_column.a.text\n",
    "                year = title_column.span.text.strip('()')\n",
    "                rating = rating_column.text.strip()\n",
    "                movies.append({'Title': title, 'Year': year, 'Rating': rating})\n",
    "        return movies\n",
    "    else:\n",
    "        print(\"Failed to retrieve data from IMDb.\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    top_100_movies = get_top_100_movies()\n",
    "    if top_100_movies:\n",
    "        df = pd.DataFrame(top_100_movies)\n",
    "        print(\"Top 100 IMDb Movies Data:\")\n",
    "        print(df)\n",
    "        df.to_csv('top_100_imdb_movies.csv', index=False)\n",
    "    else:\n",
    "        print(\"No data retrieved.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03bf70e",
   "metadata": {},
   "source": [
    "3) Write a python program to scrape mentioned details from dineout.co.in : i) Restaurant name\n",
    "ii) Cuisine iii) Location iv) Ratings v) Image URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e524947c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_dineout():\n",
    "    url = \"https://www.dineout.co.in/delhi-restaurants\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        restaurants = []\n",
    "        for restaurant in soup.find_all('div', class_='restnt-info cursor'):\n",
    "            name = restaurant.find('span', class_='restnt-info-title')\n",
    "            cuisine = restaurant.find('span', class_='double-line-ellipsis')\n",
    "            location = restaurant.find('span', class_='restnt-Location-text')\n",
    "            ratings = restaurant.find('div', class_='restaurant-rating')\n",
    "            image_url = restaurant.find('img')['data-original']\n",
    "            restaurants.append({'Name': name, 'Cuisine': cuisine, 'Location': location, 'Ratings': ratings, 'Image_URL': image_url})\n",
    "        return restaurants\n",
    "    else:\n",
    "        print(\"Failed to retrieve data from dineout.co.in.\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    restaurant_data = scrape_dineout()\n",
    "    if restaurant_data:\n",
    "        print(\"Scraped restaurant details:\")\n",
    "        for restaurant in restaurant_data:\n",
    "            print(\"Name:\", restaurant['Name'])\n",
    "            print(\"Cuisine:\", restaurant['Cuisine'])\n",
    "            print(\"Location:\", restaurant['Location'])\n",
    "            print(\"Ratings:\", restaurant['Ratings'])\n",
    "            print(\"Image URL:\", restaurant['Image_URL'])\n",
    "            print()\n",
    "    else:\n",
    "        print(\"No data retrieved.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcd8680",
   "metadata": {},
   "source": [
    "4) Write s python program to display list of respected former finance minister of India(i.e.\n",
    "Name , Term of office) from https://presidentofindia.nic.in/former-presidents.htm and make\n",
    "data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b8ad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_former_finance_ministers():\n",
    "    url = \"https://presidentofindia.nic.in/former-presidents.htm\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        finance_ministers = []\n",
    "        for table_row in soup.find_all('tr'):\n",
    "            columns = table_row.find_all('td')\n",
    "            if len(columns) >= 2:\n",
    "                name = columns[0].text.strip()\n",
    "                term_of_office = columns[1].text.strip()\n",
    "                finance_ministers.append({'Name': name, 'Term of Office': term_of_office})\n",
    "        return finance_ministers\n",
    "    else:\n",
    "        print(\"Failed to retrieve data from the website.\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    finance_ministers_data = scrape_former_finance_ministers()\n",
    "    if finance_ministers_data:\n",
    "        df = pd.DataFrame(finance_ministers_data)\n",
    "        print(\"Former Finance Ministers of India:\")\n",
    "        print(df)\n",
    "        df.to_csv('former_finance_ministers.csv', index=False)\n",
    "    else:\n",
    "        print(\"No data retrieved.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d044afee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8956f455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06895785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec9784e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
